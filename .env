OPENAI_BASE_URL=http://127.0.0.1:8080
OPENAI_API_KEY=test
OPENAI_MODEL=llama3.1
# Sentence Transformer Model Path. Use download_model.py to download
MODEL_NAME=intfloat/multilingual-e5-large
MODEL_PATH=./models/intfloat/multilingual-e5-large

# Tokenizer. Use download_tokenizer.py to download
TOKENIZER_NAME=bert-base-multilingual-cased
TOKENIZER_PATH=./models/bert-base-multilingual-cased

# Maximum Number of Tokens for Chunking
MAX_TOKENS=4096  # Adjust based on your needs

SYSTEM_INSTRUCTION="
You're a Text Summarizer. You will follow the following guidelines.
1. If the document is big then the document will be split into multiple parts and the summary of previous parts will be provided to you as context.
2. Use the context to construct a coherent summary of the text you are provided. For example the ideas and the logic should be a continuation from the previous parts.
3. Create meaningful titles and sub-titles. Do not write for example 'Part 1 of 3'.
3. You will write a summary that is detailed, thorough, in-depth, and complex, while maintaining clarity and conciseness and coherence.
4. Include the main ideas and essential information, eliminating extraneous language and focusing on critical aspects.
5. Rely strictly on the text provided, without including external information.
6. Format the summary in markdown for easy understanding. Use bullet list or table if applicable.
7. You will not write anything else other than the summary.
By following this optimized prompt, you will produce an effective summary that captures the essence of the given text in a clear, concise, and reader-friendly manner.
"
EASYOCR_MODELS_PATH=./models/easyocr

##################### RAG
# Elasticsearch Configuration
ES_HOST_URL=http://127.0.0.1:9200  # Replace with your Elasticsearch host URL
ES_USERNAME=elastic  # Replace with your Elasticsearch username
ES_PASSWORD=changeme  # Replace with your Elasticsearch password

# Sentence Transformer Model Path. Use download_model.py to download
MODEL_NAME=intfloat/multilingual-e5-large
MODEL_PATH=./models/intfloat/multilingual-e5-large

# Tokenizer. Use download_tokenizer.py to download
TOKENIZER_NAME=bert-base-multilingual-cased
TOKENIZER_PATH=./models/bert-base-multilingual-cased

# Maximum Number of Tokens for Chunking
MAX_TOKENS=512  # Adjust based on your needs

# LLM configuration
TEMPERATURE=0.4 # 0.1
TOP_P=None # 0.95
FREQUENCY_PENALTY=None # 0.0
PRESENCE_PENALTY=None # 0.0
TOP_K=None

# OpenAI API Configuration
OPENAI_BASE_URL=http://127.0.0.1:8080  # Replace with your OpenAI API base URL
OPENAI_API_KEY=test  # Replace with your OpenAI API key
OPENAI_MODEL=llama3.1  # Replace with the OpenAI model you want to use

# Instruction Prompt
#INSTRUCTION_PROMPT="You are an intelligent assistant retrieving information from documents using Retrieval-Augmented Generation and answers users questions based on provided sources.If you don't know the answer, just say that you don't know. Provide clear, detailed, and accurate information using the retrieved context. You will be provided with Document_Name, Timestamp and Context. Responses will be specific, accurate, and offer a detailed explanation, proceeding step by step, to arrive at a conclusive answer, ensuring clarity and educational value. Use markdown and tables to structure your response. Answer in the following format Reference: Exact Document Name \n Added on: Timestamp \n Answer: "
INSTRUCTION_PROMPT="
Rules:
1. You are an intelligent assistant designed to retrieve information from documents using Retrieval-Augmented Generation.
2. Your task is to answer users' questions based on the provided context.
3.  Answers should be based ONLY on the context, NOT on your prior knowledge.
4. If no context is provided, say clearly that you don't know the Answer.
5. Your responses should be clear, detailed, and accurate, utilizing the retrieved context. Use markdown for formatting and tables/bullet-points where applicable to organize information clearly.
6. Your answer should always contain references of Document Names and Timestamps.
7. You will be provided with the following details:
- **Document Name**
- **Timestamp**
- **Context**
"

# Index management
DEFAULT_DIMS=1024

# Search Settings
SIMILARITY_TYPE=max_inner_product # dot_product, cosine, max_inner_product (Used when creating index)
NUM_CANDIDATES=20 # More for accurate search, less for faster speed, Note: NUM_CANDIDATES > NUM_RESULTS
NUM_RESULTS=10  # Adjust the number of search results returned by Elasticsearch
MIN_SCORE=1.78 # Minimum search score to filter results

# UI Configuration
INTERVAL=6000  # Refresh interval in milliseconds
DEFAULT_DISPLAY_METRICS=False
